break
}
}
#left_leaves[[node]] contains the leaves left-descended from node
#right_leaves[[node]] contains the leaves right-descended from node
left_leaves = NULL
right_leaves = NULL
left_leaves[[max(internal_nodes)+1]] = rep(0,5)
right_leaves[[max(internal_nodes)+1]] = rep(0,5)
for (node in internal_nodes){
left_descend = NULL
right_descend = NULL
descend = descendants[[node]]
left = descend[1]
right = descend[2]
#if the descendant is a leaf we can termiante
if((left %in% leaves)==TRUE){
left_descend = left
} else {
#cycle through all of the leaves and see which are left descendants
for (nodes in leaves){
if((left %in% ancestors[[nodes]])==TRUE){
left_descend = c(left_descend,nodes)
}
}
}
left_leaves[[node]] = left_descend
#if the descendant is a leaf we can termiante
if((right %in% leaves)==TRUE){
right_descend = right
} else {
#cycle through all of the leaves and see which are right descendants
for (nodes in leaves){
if((right %in% ancestors[[nodes]])==TRUE){
right_descend = c(right_descend,nodes)
}
}
}
right_leaves[[node]] = right_descend
}
left_leaves[[max(internal_nodes)+1]] = NULL
right_leaves[[max(internal_nodes)+1]] = NULL
#leaf_success[[leaf]] contains the nodes from which leaf is left-descended
leaf_success = NULL
leaf_success_C = NULL
leaf_success[[max(leaves)+1]] = rep(0,5)
leaf_success_C[[max(leaves)+1]] = rep(0,5)
for (leaf in leaves){
node_list=NULL
node_list = c(leaf,ancestors[[leaf]])
successes = NULL
for (node in ancestors[[leaf]]){
if ((descendants[[node]][1] %in% node_list)==TRUE){
successes = c(successes,node)
}
}
if (is.null(successes)==FALSE){
leaf_success[[leaf]] = successes
leaf_success_C[[leaf]] = successes - 1
} else {
leaf_success_C[[leaf]] = -1
}
}
leaf_success[[max(leaves)+1]]  = NULL
leaf_success_C[[max(leaves)+1]]  = NULL
#leaf_failures[[leaf]] contains the nodes from which leaf is right-descended
leaf_failures = NULL
leaf_failures[[max(leaves)+1]] = rep(0,5)
leaf_failures_C = NULL
leaf_failures_C[[max(leaves)+1]] = rep(0,5)
for (leaf in leaves){
node_list=NULL
node_list = c(leaf,ancestors[[leaf]])
failures = NULL
for (node in ancestors[[leaf]]){
if ((descendants[[node]][2] %in% node_list)==TRUE){
failures = c(failures,node)
}
}
if (is.null(failures)==FALSE){
leaf_failures[[leaf]] = failures
leaf_failures_C[[leaf]] = failures - 1
} else {
leaf_failures_C[[leaf]] = -1
}
}
leaf_failures[[max(leaves)+1]] = NULL
leaf_failures_C[[max(leaves)+1]] = NULL
#come up with a mapping from internal nodes to 1:p
#node_map[internal_nodes] in {1,2,dots,p}
p = length(internal_nodes)
node_map = rep(0,A)
for(x in 1:p){
node_map[internal_nodes[x]] = x
}
#find number of samples
D = ncol(test_dtm)
#Initialize an extra count matrix
extra_dtm = matrix(0,nrow=V,ncol=D)
#if there are less than 3 sequencing reads, it stays in the test set
#This doesn't matter because the count is so low
#If it is more than three, we split about in half
#This is a janky way to handle even and odd counts
for(d in 1:D){
for(v in 1:V){
total = test_dtm[v,d]
if( total > 3){
extra_dtm[v,d] = sample( (round(total/2) - 1):(round(total/2) + 1),1)
test_dtm[v,d] = test_dtm[v,d]-extra_dtm[v,d]
}
}
}
#convert test_dtm count data to list of vectors of tokens
docs = NULL
docs[[D+1]] = rep(0,10000)
docs_C = NULL
for (d in 1:D){ #for each document
doc = NULL
for(v in 1:V){
doc = c(doc,rep(v,test_dtm[v,d]))
}
doc = doc[sample(1:length(doc),replace = FALSE)]
docs[[d]] = doc
docs_C[[d]] = docs[[d]] - 1
}
docs[[D+1]] = NULL
#1 Initialize subocmmunity assignments to sequencing in each sample
ta = lapply(docs, function(x) rep(0, length(x))) # initialize topic assignment list
ta_C = lapply(docs, function(x) rep(0, length(x)))
#2 Generate word-topic (ASV-subcommunity) count matrix.
wt = matrix(0, K, V) # wt[k,v] is the count of word v assigned to topic k
#3 Initialize document-topic (sample-subcommunity) count matrix
dt = matrix(0, length(docs), K) #dt[d,k] is count of topic k in document d
K
model$Mean_Post_Phi_d
dim(model$Mean_Post_Phi_d)
#extract structures from phyloseq
tree.edge = phyloseq::phy_tree(ps)$edge
test_dtm = phyloseq::otu_table(ps)
#load K from model
K = dim(model$Mean_Post_Phi_d)[2]
#find characteristics of tree
#find the root node
root = setdiff(tree.edge[,1],tree.edge[,2])
#find the internal nodes and reorder
internal_nodes = unique(tree.edge[,1])
internal_nodes = sort(internal_nodes)
internal_nodes_C = internal_nodes - 1
#find the maximum of the internal nodes
A = max(internal_nodes)
#find the set of leaves
leaves = setdiff(tree.edge[,2],tree.edge[,1])
#find the number of leaves
V = length(leaves)
#descendants[[i]] contains the two immediate descendants of node i
descendants = NULL
descendants_mat = matrix(0,ncol=2,nrow=max(tree.edge))
for(i in 1:max(tree.edge)){
if (sum(which(tree.edge[,1]==i))>0){
descendants[[i]] = tree.edge[which(tree.edge[,1] == i),2]
descendants_mat[i,] = descendants[[i]]
}
}
descendants_mat_C = descendants_mat - 1
#parents[i] contains the parent of node i
parents = NULL
for (i in 1:max(tree.edge)){
if (sum(which(tree.edge[,2]==i))>0){
parents[i] = tree.edge[which(tree.edge[,2]==i),1]
}
}
#ancestors[[i]] contains all of the ancestors of node i
ancestors = NULL
ancestors_C = NULL
for (i in 1:max(tree.edge)){
up=NULL
parent = parents[i]
while (is.na(parents[parent])==FALSE){
up = c(up,parent)
parent = parents[parent]
}
ancestors[[i]] = c(up,parent) #Adds the root of the tree as well
ancestors_C[[i]] = ancestors[[i]]-1
}
#layers[[i]] containts the nodes in the i^th layer of the tree
#layers[[1]] is the root node, layers[[2]] is the root nodes children, etc
layers = NULL
#initialize layer 2 and 1
#have to do an n-tuple (n>1) first, o/w this explodes
layers[[2]] = descendants[[root]]
layers[[1]] = root
for (i in 3:max(tree.edge)){
descend = NULL
for (j in 1:length(layers[[i-1]])){
descend = c(descend,descendants[[layers[[i-1]][j]]])
}
if ((sum(descend)>0)==TRUE){
layers[[i]] = descend
} else{
break
}
}
#left_leaves[[node]] contains the leaves left-descended from node
#right_leaves[[node]] contains the leaves right-descended from node
left_leaves = NULL
right_leaves = NULL
left_leaves[[max(internal_nodes)+1]] = rep(0,5)
right_leaves[[max(internal_nodes)+1]] = rep(0,5)
for (node in internal_nodes){
left_descend = NULL
right_descend = NULL
descend = descendants[[node]]
left = descend[1]
right = descend[2]
#if the descendant is a leaf we can termiante
if((left %in% leaves)==TRUE){
left_descend = left
} else {
#cycle through all of the leaves and see which are left descendants
for (nodes in leaves){
if((left %in% ancestors[[nodes]])==TRUE){
left_descend = c(left_descend,nodes)
}
}
}
left_leaves[[node]] = left_descend
#if the descendant is a leaf we can termiante
if((right %in% leaves)==TRUE){
right_descend = right
} else {
#cycle through all of the leaves and see which are right descendants
for (nodes in leaves){
if((right %in% ancestors[[nodes]])==TRUE){
right_descend = c(right_descend,nodes)
}
}
}
right_leaves[[node]] = right_descend
}
left_leaves[[max(internal_nodes)+1]] = NULL
right_leaves[[max(internal_nodes)+1]] = NULL
#leaf_success[[leaf]] contains the nodes from which leaf is left-descended
leaf_success = NULL
leaf_success_C = NULL
leaf_success[[max(leaves)+1]] = rep(0,5)
leaf_success_C[[max(leaves)+1]] = rep(0,5)
for (leaf in leaves){
node_list=NULL
node_list = c(leaf,ancestors[[leaf]])
successes = NULL
for (node in ancestors[[leaf]]){
if ((descendants[[node]][1] %in% node_list)==TRUE){
successes = c(successes,node)
}
}
if (is.null(successes)==FALSE){
leaf_success[[leaf]] = successes
leaf_success_C[[leaf]] = successes - 1
} else {
leaf_success_C[[leaf]] = -1
}
}
leaf_success[[max(leaves)+1]]  = NULL
leaf_success_C[[max(leaves)+1]]  = NULL
#leaf_failures[[leaf]] contains the nodes from which leaf is right-descended
leaf_failures = NULL
leaf_failures[[max(leaves)+1]] = rep(0,5)
leaf_failures_C = NULL
leaf_failures_C[[max(leaves)+1]] = rep(0,5)
for (leaf in leaves){
node_list=NULL
node_list = c(leaf,ancestors[[leaf]])
failures = NULL
for (node in ancestors[[leaf]]){
if ((descendants[[node]][2] %in% node_list)==TRUE){
failures = c(failures,node)
}
}
if (is.null(failures)==FALSE){
leaf_failures[[leaf]] = failures
leaf_failures_C[[leaf]] = failures - 1
} else {
leaf_failures_C[[leaf]] = -1
}
}
leaf_failures[[max(leaves)+1]] = NULL
leaf_failures_C[[max(leaves)+1]] = NULL
#come up with a mapping from internal nodes to 1:p
#node_map[internal_nodes] in {1,2,dots,p}
p = length(internal_nodes)
node_map = rep(0,A)
for(x in 1:p){
node_map[internal_nodes[x]] = x
}
#find number of samples
D = ncol(test_dtm)
#Initialize an extra count matrix
extra_dtm = matrix(0,nrow=V,ncol=D)
#if there are less than 3 sequencing reads, it stays in the test set
#This doesn't matter because the count is so low
#If it is more than three, we split about in half
#This is a janky way to handle even and odd counts
for(d in 1:D){
for(v in 1:V){
total = test_dtm[v,d]
if( total > 3){
extra_dtm[v,d] = sample( (round(total/2) - 1):(round(total/2) + 1),1)
test_dtm[v,d] = test_dtm[v,d]-extra_dtm[v,d]
}
}
}
#convert test_dtm count data to list of vectors of tokens
docs = NULL
docs[[D+1]] = rep(0,10000)
docs_C = NULL
for (d in 1:D){ #for each document
doc = NULL
for(v in 1:V){
doc = c(doc,rep(v,test_dtm[v,d]))
}
doc = doc[sample(1:length(doc),replace = FALSE)]
docs[[d]] = doc
docs_C[[d]] = docs[[d]] - 1
}
docs[[D+1]] = NULL
#1 Initialize subocmmunity assignments to sequencing in each sample
ta = lapply(docs, function(x) rep(0, length(x))) # initialize topic assignment list
ta_C = lapply(docs, function(x) rep(0, length(x)))
#2 Generate word-topic (ASV-subcommunity) count matrix.
wt = matrix(0, K, V) # wt[k,v] is the count of word v assigned to topic k
#3 Initialize document-topic (sample-subcommunity) count matrix
dt = matrix(0, length(docs), K) #dt[d,k] is count of topic k in document d
#4 Initialize counts of words-by-document-by topic
# (ASVs-by-sample-by-subcommunity)
wc_dwt = array(0,dim=c(D,V,K))
#wc_dwt[d,w,k] is count of word w assigned to topic k in document d
#5 Initialie counts at each node by document and topic (sample and subcommunity)
nc_dnt =  array(0,dim=c(D,max(tree.edge),K)) #node-count-by-document-by-topic
for(d in 1:length(docs)){ # for each document
for(w in 1:length(docs[[d]])){ # for each token in document d
ta[[d]][w] = sample(1:K, 1) # randomly assign topic to token
ta_C[[d]][w] = ta[[d]][w]-1
ti = ta[[d]][w] # topic index
wi = docs[[d]][w] # word associated with token w
wt[ti,wi] = wt[ti,wi]+1 # update word-topic count matrix
}
#Use subcommunity-assignment vector to:
#   find sample-subcommunity (dt) counts
#   find ASVs-by-sample-by-subcommunity (wc_dwt) counts
for(k in 1:K){ # for each topic k
dt[d,k] = sum(ta[[d]]==k) # count tokens in document d assigned to topic t
ta.temp = docs[[d]][which(ta[[d]]==k)]
for(w in 1:length(ta.temp)){ # for each word
ti = k # topic index
wi = ta.temp[w] # wordID for token w
wc_dwt[d,wi,ti] = wc_dwt[d,wi,ti]+1 # update word-topic count matrix
}
nc_dnt[d,1:max(leaves),k]=wc_dwt[d,,k] #word-count,doc d,top k on the leaves
#recursively go up the tree to find counts on all nodes
for(i in length(layers):1){
for (j in 1:length(layers[[i]])){
if (length(descendants[[layers[[i]][j]]])>0){
nc_dnt[d,layers[[i]][j],k] = sum(nc_dnt[d,descendants[[layers[[i]][j]]],k])
}
}
}
}
}
#Initialize kappa
#kappa_pdk[p,d,k] is kappa for node p in sample d and subcommunity k
kappa_pdk = array(0,dim=c(p,D,K))
for(k in 1:K){
for(a in 1:p){
for(d in 1:D){
kappa_pdk[a,d,k] = nc_dnt[d,descendants[[internal_nodes[a]]][1],k] - nc_dnt[d,internal_nodes[a],k]/2
}
}
}
#initialize phi according to a Dir(1) distribution
#phi_dk[d,k] is the proportion of subcommunity k in sample d
phi_dk = matrix(0,nrow=D,ncol=K)
for(d in 1:D){
for(k in 1:K){
phi_dk[d,] = stats::rgamma(K,1,1)
}
phi_dk[d,] = phi_dk[d,]/sum(phi_dk[d,])
}
#initialize psi according to a N(0,I) distribution
#psi_pdk[p,d,k] is the log-odds at node p in sample d and subcommunity k
psi_pdk = array(0,dim=c(p,D,K))
for(k in 1:K){
for(d in 1:D){
psi_pdk[,d,k] = chol(diag(p)) %*% matrix(stats::rnorm(p,0,1),nrow=p)
}
}
#convert log-odds psi_pdk into probabilities theta_kda
#theta_kda[k,d,a] is the probability in subcommunity k, sample d, and node a
theta_kda = array(0,dim=c(K,D,A))
for (k in 1:K){
for (d in 1:D){
for (a in 1:p){
theta_kda[k,d,internal_nodes[a]] = exp(psi_pdk[a,d,k])/(1+exp(psi_pdk[a,d,k]))
}
}
}
#find the multinoimal distribution on the leaves implied by the theta_kda
#beta_kdv[k,d,1:V] is the multinomial distirubtion on the V leaves in
#subcommunity k and sample d
beta_kdv = array(0,dim=c(K,D,V))
for (d in 1:D){
for (k in 1:K){
for (leaf in leaves){ #for each leaf
beta_kdv[k,d,leaf] = prod(theta_kda[k,d,leaf_success[[leaf]]])*prod((1-theta_kda[k,d,leaf_failures[[leaf]]]))
}
}
}
#initialize v_pdk, the polya-gamma auxiliary variables
# v_pdk[p,d,k] is the PG variable associated with node p in sample d and subcommunity k
v_pdk = array(0,dim=c(p,D,K))
for(k in 1:K){
for(d in 1:D){
for(a in 1:p){
if(nc_dnt[d,internal_nodes[a],k]<1){
v_pdk[a,d,k] = 0
} else {
v_pdk[a,d,k] = pgdraw::pgdraw(nc_dnt[d,internal_nodes[a],k],psi_pdk[a,d,k])
}
}
}
}
#first load markov chains
mu_chain_k_ip = model$Chain_Mu
Sigma_chain_k_ipp = model$Chain_Sigma
#posterior mu mean
post_mu_pk = matrix(0,nrow=p,ncol=K)
for(k in 1:K){
for(a in 1:p){
post_mu_pk[a,k] = mean(mu_chain_k_ip[[k]][,a])
}
}
#posterior Sigma means
post_Sigma_ppk = array(0,dim=c(p,p,K))
for(k in 1:K){
entry = Sigma_chain_k_ipp[[k]]
runtime = dim(entry)[1]
temp = matrix(0,nrow=p,ncol=p)
for(i in 1:runtime){
temp = temp + entry[i,,]
}
post_Sigma_ppk[,,k] = temp/runtime
}
post_Sigma_ppk[1,1,]
#initialize covariance matrices Sigma_ppk from the posterior means
#Sigma_ppk[,,k] is the covariance matrix associated with subcommunity k
Sigma_ppk = array(0,dim=c(p,p,K))
for(k in 1:K){
Sigma_ppk[,,k] = post_Sigma_ppk[,,k]
}
#find the inverse matrices W_ppk
#W_ppk[,,k] is the inverse of Sigma_ppk[,,k]
W_ppk = array(0,dim=c(p,p,K))
for(k in 1:K){
for(a in 1:p){
W_ppk[a,a,k] = 1/Sigma_ppk[a,a,k]
}
}
#initialize mean vectors mu_pk from the posterior means
#mu_pk[p,k] is the mean log-odds for node p in subcommunity k
mu_pk = matrix(0,nrow=p,ncol=K)
for(k in 1:K){
mu_pk[,k] = post_mu_pk[,k]
}
#Pre-allocate chains
chain_phi_dki = array(0,dim=c(D,K,iterations))
psi_chain_k_ipd = NULL
for(k in 1:K){
psi_chain_k_ipd[[k]] = array(0,dim=c(iterations,p,D))
}
2+2
Rcpp::compileAttributes()
devtools::document()
devtools::install()
library(devtools)
library(Rcpp)
library(RcppArmadillo)
library(roxygen2)
Rcpp::compileAttributes()
devtools::document()
devtools::install(build_vignettes = TRUE)
browseVignettes("LTNLDA")
library(Rcpp)
library(RcppArmadillo)
library(roxygen2)
library(devtools)
Rcpp::compileAttributes()
devtools::document()
devtools::install(build_vignettes = TRUE)
library(LTNLDA)
Rcpp::compileAttributes()
devtools::document()
devtools::install(build_vignettes = TRUE)
library(devtools)
library(Rcpp)
library(RcppArmadillo)
devtools::document()
Rcpp::compileAttributes()
Rcpp::compileAttributes()
devtools::document()
Rcpp::compileAttributes()
devtools::document()
Rcpp::compileAttributes()
devtools::document()
